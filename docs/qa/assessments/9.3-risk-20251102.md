# Risk Profile: Story 9.3

Date: 2025-11-02
Reviewer: Quinn (Test Architect)

## Executive Summary

- **Total Risks Identified**: 11
- **Critical Risks**: 0
- **High Risks**: 3
- **Medium Risks**: 6
- **Low Risks**: 2
- **Overall Risk Score**: 67/100 (Moderate Risk)

**Key Findings:**

- No critical risks identified - story has solid foundation with existing orchestrator service
- Primary high risks: public endpoint abuse, orchestrator service dependencies, latency from sequential calls
- Security risks mitigated by existing rate limiting middleware
- Performance risks are manageable with proper async patterns and timeouts
- Good error handling patterns available from existing codebase

## Critical Risks Requiring Immediate Attention

_None identified - all risks are manageable with existing infrastructure and proper implementation._

## High Risks (Score 6)

### 1. SEC-001: Public Endpoint Abuse Potential

**Score: 6 (High)**
**Probability**: Medium - Public endpoint without user authentication creates abuse opportunity
**Impact**: High - Potential for cost abuse via DeepSeek API, resource exhaustion, service degradation

**Description:**

The `/api/chat` endpoint has no user authentication (per AC 9 - MVP scope decision). This allows:
- Unlimited usage by any party, leading to potential cost abuse via expensive DeepSeek API calls
- Resource exhaustion attacks (memory, CPU from orchestrator operations)
- DoS via rapid requests exhausting rate limiter capacity
- Systematic document corpus scraping through chat queries
- No ability to track or limit usage per user/organization

**Affected Components:**

- `app/api/routes/chat.py` (to be created)
- Rate limiting middleware
- Chat orchestrator service (increased load)
- DeepSeek API cost tracking

**Detection Method:**

Story acceptance criteria explicitly states "No user authentication required (MVP scope - public endpoint)". Rate limiting middleware exists but may not be sufficient for chat endpoint's resource-intensive nature.

**Mitigation:**

- **Preventive**: Verify rate limiting middleware applies to `/api/chat` endpoint (not in excluded paths)
- **Preventive**: Ensure rate limiting is sufficient for chat endpoint's resource-intensive nature (may need stricter limits than search)
- **Preventive**: Implement request cost tracking and alerts for unusual usage patterns
- **Preventive**: Add monitoring for request patterns indicating scraping/abuse
- **Detective**: Monitor DeepSeek API usage and costs per IP/client
- **Corrective**: Have rollback plan if abuse detected; document as known MVP limitation

**Testing Requirements:**

- Test rate limiting middleware applies correctly to `/api/chat`
- Load testing with high request volume to verify rate limiting effectiveness
- Monitor for abuse patterns (rapid queries, systematic document exploration)
- Verify chat endpoint is not excluded from rate limiting

**Residual Risk**: Medium - Acceptable for MVP with proper rate limiting and monitoring

**Owner**: Dev + Ops
**Timeline**: Before deployment, continuous monitoring post-deployment

### 2. TECH-001: Service Dependency Chain Failures

**Score: 6 (High)**
**Probability**: Medium - Multiple dependent services increase failure likelihood
**Impact**: High - Complete chat functionality unavailable if orchestrator or any dependency fails

**Description:**

Chat endpoint depends on chat orchestrator service, which in turn depends on: hybrid search service → reranker service → DeepSeek API. Failure at any point causes complete chat failure. Error handling must properly catch and format errors from each layer.

**Affected Components:**

- Chat orchestrator service (`app/services/chat_orchestrator.py`)
- Hybrid search service
- Reranker service
- DeepSeek API client

**Detection Method:**

Integration points identified in story: orchestrator methods `retrieve_candidates()`, `rerank()`, `synthesize_answer()` all can raise RuntimeError or Exception.

**Mitigation:**

- **Preventive**: Implement comprehensive try-catch blocks around orchestrator calls
- **Preventive**: Map orchestrator exceptions to standardized error responses following error model
- **Preventive**: Ensure error middleware handles chat endpoint gracefully
- **Detective**: Add specific error logging for each service failure point
- **Corrective**: Return informative error messages following standardized error model

**Testing Requirements:**

- Integration tests with orchestrator service failure scenarios
- Mock orchestrator failures and verify error handling
- Test error response formatting matches error model
- Verify error middleware processes chat endpoint errors correctly

**Residual Risk**: Medium - Can be mitigated with proper error handling patterns from existing codebase

**Owner**: Dev
**Timeline**: During implementation

### 3. PERF-001: Sequential Service Calls Cause High Latency

**Score: 6 (High)**
**Probability**: High - Sequential calls (retrieve → rerank → synthesize) are inherent to design
**Impact**: Medium - User experience degradation, potential timeouts

**Description:**

Chat flow requires sequential service calls: hybrid search → reranker → DeepSeek LLM. Each step adds latency. DeepSeek API calls can be particularly slow (several seconds). Total latency may exceed user expectations or timeout thresholds. Without streaming (per AC 10), users wait with no feedback.

**Affected Components:**

- Chat orchestrator service flow
- API endpoint response time
- User experience

**Detection Method:**

Story integration flow shows sequential calls: `retrieve_candidates()` → `rerank()` → `synthesize_answer()`. DeepSeek API latency is inherently slow.

**Mitigation:**

- **Preventive**: Implement proper async/await patterns to avoid blocking event loop
- **Preventive**: Set appropriate timeout values for DeepSeek API calls (30 seconds recommended)
- **Preventive**: Add latency metrics and logging
- **Detective**: Monitor P50/P95/P99 latencies for chat endpoint
- **Corrective**: Consider adding response caching for similar queries in future (post-MVP)

**Testing Requirements:**

- Load testing with realistic query patterns
- Latency testing under various system loads
- Timeout handling tests (verify 30s timeout works correctly)
- Performance benchmarks (target < 10s P95 latency for MVP)

**Residual Risk**: Medium - LLM API latency is inherent but manageable with proper async patterns and timeouts

**Owner**: Dev
**Timeline**: Before deployment

## Medium Risks (Score 4)

### 4. SEC-002: Input Sanitization and Validation

**Score: 4 (Medium)**
**Probability**: Medium - Depends on implementation quality
**Impact**: Medium - Potential prompt injection attacks, XSS via citations, input abuse

**Description:**

User message input (1-1000 characters) requires sanitization. Risks include:
- Prompt injection attacks against LLM (attempting to override system instructions in orchestrator)
- XSS if citations are rendered in frontend without sanitization
- Malformed input causing orchestrator errors

**Affected Components:**

- Chat request schema validation
- Chat orchestrator (prompt construction)
- Frontend citation rendering

**Mitigation:**

- **Preventive**: Implement input validation (length, character restrictions via Pydantic)
- **Preventive**: Sanitize user messages before sending to orchestrator (strip control characters)
- **Preventive**: Follow existing search endpoint validation patterns
- **Testing Requirements**: Security testing with malicious inputs, prompt injection attempts

**Residual Risk**: Low - Proper validation and sanitization mitigate most risks

**Owner**: Dev
**Timeline**: During implementation

### 5. TECH-002: UUID and Schema Validation Complexity

**Score: 4 (Medium)**
**Probability**: Low - FastAPI/Pydantic provide good validation
**Impact**: Medium - Invalid requests cause 400 errors, may confuse users

**Description:**

Conversation ID must be UUID format. Message must be 1-1000 characters. Validation failures need to return clear error messages following standardized error model. Invalid UUID format or empty/missing fields need proper handling.

**Affected Components:**

- Chat request schema (`app/schemas/chat.py`)
- API endpoint validation
- Error response formatting

**Mitigation:**

- **Preventive**: Use Pydantic models with proper validators (UUID type, string length constraints)
- **Preventive**: Ensure error messages follow standardized error model
- **Preventive**: Validate UUID format using Python uuid module or Pydantic UUID type
- **Testing Requirements**: Test all validation scenarios (invalid UUID, empty message, too long message, missing fields)

**Residual Risk**: Low - FastAPI/Pydantic handle most cases automatically

**Owner**: Dev
**Timeline**: During implementation

### 6. DATA-001: User Input Logging and Privacy

**Score: 4 (Medium)**
**Probability**: Medium - Logging user messages is likely for debugging
**Impact**: Medium - Privacy concerns, potential PII exposure in logs

**Description:**

Chat requests will likely be logged for debugging (AC 8: logging for chat interactions). User messages may contain sensitive information or PII. Without authentication, there's no way to implement user-level data retention policies.

**Affected Components:**

- Chat endpoint logging
- Log storage and retention policies

**Mitigation:**

- **Preventive**: Truncate or hash user messages in logs (log first 50 chars + hash)
- **Preventive**: Implement log retention policies
- **Preventive**: Avoid logging full conversation content
- **Preventive**: Follow existing search endpoint logging patterns
- **Testing Requirements**: Verify logging doesn't capture full user messages unnecessarily

**Residual Risk**: Low - Proper logging practices mitigate privacy concerns

**Owner**: Dev + Security
**Timeline**: Before deployment

### 7. PERF-002: DeepSeek API Rate Limiting

**Score: 4 (Medium)**
**Probability**: Medium - Depends on API plan limits and concurrent usage
**Impact**: Medium - Service unavailable if API quota exceeded

**Description:**

DeepSeek API has rate limits that may be exceeded under load. No clear strategy for handling rate limit responses or queuing requests. Rate limit errors from DeepSeek may not be properly handled, leading to 500 errors instead of informative messages.

**Affected Components:**

- DeepSeek client (`app/deps/deepseek_client.py`)
- Chat orchestrator service
- Error handling in chat API endpoint

**Mitigation:**

- **Preventive**: Understand DeepSeek API rate limits and configure accordingly
- **Preventive**: Add retry logic with exponential backoff for rate limit errors in orchestrator
- **Detective**: Monitor DeepSeek API response codes and rate limit headers
- **Corrective**: Return 429 status code with Retry-After header when rate limited

**Testing Requirements:**

- Test handling of DeepSeek API rate limit responses
- Load testing to identify rate limit thresholds
- Verify proper error responses (429 status) when rate limited

**Residual Risk**: Low - Proper error handling can prevent user-facing failures

**Owner**: Dev
**Timeline**: Before deployment

### 8. OPS-001: Missing Operational Monitoring

**Score: 4 (Medium)**
**Probability**: Medium - Monitoring not yet specified for chat endpoint
**Impact**: Medium - Incidents may go undetected, difficult to diagnose issues

**Description:**

No specific monitoring mentioned for chat endpoint beyond basic logging (AC 8). Missing:
- Chat-specific metrics (latency, error rates, usage patterns)
- DeepSeek API usage metrics
- Conversation tracking metrics
- Alerting for chat endpoint failures

**Affected Components:**

- Chat endpoint implementation
- Monitoring/observability infrastructure

**Mitigation:**

- **Preventive**: Add structured logging with request IDs for traceability
- **Preventive**: Implement metrics collection (latency, error rates, request counts) following search endpoint patterns
- **Preventive**: Add alerting for high error rates or latency spikes
- **Detective**: Create dashboards for chat endpoint health
- **Corrective**: Ensure logging captures enough context for debugging

**Testing Requirements:**

- Verify logging captures all necessary context
- Test that metrics are collected correctly
- Verify alerting triggers appropriately

**Residual Risk**: Low - Can be added incrementally but should be prioritized

**Owner**: Dev + Ops
**Timeline**: Before deployment, incremental improvements post-deployment

### 9. TECH-003: Response Schema Transformation

**Score: 4 (Medium)**
**Probability**: Low - Schema transformation is straightforward but requires careful mapping
**Impact**: Medium - Incorrect formatting leads to frontend errors or missing citations

**Description:**

Orchestrator returns answer string and chunks. API must transform into response schema with citations array. Citation mapping must correctly extract doc_id, chunk_id, page_from, page_to, score, text from reranked chunks returned by orchestrator.

**Affected Components:**

- Chat API endpoint
- Response formatting logic

**Mitigation:**

- **Preventive**: Implement comprehensive unit tests for response transformation
- **Preventive**: Validate response schema matches specification exactly
- **Preventive**: Handle missing fields gracefully with defaults
- **Testing Requirements**: Unit tests for all response formatting scenarios, edge cases (missing fields, null values)

**Residual Risk**: Very Low - Straightforward transformation with proper testing

**Owner**: Dev
**Timeline**: During implementation

## Low Risks (Score 2-3)

### 10. PERF-003: No Response Caching

**Score: 3 (Low)**
**Probability**: Medium - Caching not mentioned in story
**Impact**: Low - Redundant LLM API calls waste resources and increase costs

**Description:**

Chat endpoint doesn't implement caching. Identical or similar queries will trigger full orchestrator flow and LLM API calls, increasing costs and latency. Unlike search endpoint (which has caching), chat has no caching strategy.

**Affected Components:**

- Chat endpoint implementation
- Cost optimization

**Mitigation:**

- **Preventive**: Consider implementing response caching for identical queries (hash of message + conversation_id) in future
- **Preventive**: Cache TTL should be short (e.g., 5 minutes) to ensure freshness
- **Preventive**: Monitor LLM API costs to identify caching ROI
- **Testing Requirements**: Load testing to measure cost impact of missing cache

**Residual Risk**: Low - Can be added post-MVP if cost/performance issues arise

**Owner**: Dev
**Timeline**: Post-MVP optimization

### 11. OPS-002: External Dependency (DeepSeek) Outage Impact

**Score: 2 (Low)**
**Probability**: Low - External API outages are infrequent
**Impact**: Medium - Complete chat functionality unavailable during outages

**Description:**

DeepSeek API is external dependency. Outages or maintenance windows will cause chat endpoint to fail. No fallback mechanism or alternative LLM provider.

**Affected Components:**

- DeepSeek client
- Chat functionality

**Mitigation:**

- **Preventive**: Implement proper error handling and user-friendly error messages
- **Preventive**: Monitor DeepSeek API status
- **Detective**: Alert on DeepSeek API failures
- **Corrective**: Consider multi-provider strategy in future (post-MVP)

**Residual Risk**: Low - Acceptable risk for MVP with single provider

**Owner**: Dev + Ops
**Timeline**: Post-MVP enhancement

## Risk Distribution

### By Category

- **Security**: 2 risks (1 high, 1 medium)
- **Performance**: 3 risks (1 high, 2 medium/low)
- **Technical**: 3 risks (1 high, 2 medium)
- **Data**: 1 risk (medium)
- **Operational**: 2 risks (2 medium)

### By Component

- **API Endpoint**: 5 risks (validation, error handling, logging, monitoring, schema transformation)
- **Chat Orchestrator Integration**: 2 risks (service dependencies, error handling)
- **DeepSeek Integration**: 2 risks (rate limiting, outages)
- **Infrastructure**: 2 risks (rate limiting middleware, monitoring)

## Risk-Based Testing Strategy

### Priority 1: High Risk Tests

**SEC-001 (Public Endpoint Abuse)**
- Test rate limiting middleware applies correctly to `/api/chat` endpoint
- Load testing with high request volume from single IP
- Verify rate limiting is effective for resource-intensive chat endpoint
- Monitor for abuse patterns (rapid queries, systematic exploration)

**TECH-001 (Service Dependencies)**
- Integration tests with orchestrator service failure scenarios
- Mock orchestrator failures and verify error handling
- Test error response formatting matches standardized error model
- Verify error middleware processes chat endpoint errors correctly

**PERF-001 (High Latency)**
- Load testing with realistic query patterns
- Measure P50/P95/P99 latencies
- Test timeout handling (30s timeout)
- Verify async/await patterns prevent blocking

### Priority 2: Medium Risk Tests

**SEC-002 (Input Validation)**
- Security testing with malicious inputs
- Test prompt injection attempts
- Verify input sanitization works correctly

**TECH-002 (Schema Validation)**
- Test all validation scenarios (invalid UUID, empty message, too long, missing fields)
- Verify error messages follow standardized model

**DATA-001 (Logging Privacy)**
- Verify logs don't capture full user messages
- Test log truncation/hashing

**PERF-002 (API Rate Limiting)**
- Test DeepSeek API rate limit response handling
- Load testing to identify rate limit thresholds
- Verify proper error responses (429 status)

**OPS-001 (Monitoring)**
- Verify structured logging with request IDs
- Test metrics collection (latency, error rates)

### Priority 3: Low Risk Tests

**Standard Functional Tests**
- Happy path: successful chat interaction
- Error path: service failures, validation errors
- Edge cases: empty results, no citations, very long messages
- Response schema compliance

## Risk Acceptance Criteria

### Must Fix Before Production

- All high risks affecting availability: **TECH-001** must have proper error handling
- Performance risks causing user impact: **PERF-001** must have appropriate timeouts and async patterns
- Security risks: **SEC-001** must have effective rate limiting verified

### Can Deploy with Mitigation

- **SEC-002** (Input validation): Can deploy with basic validation, enhance security testing post-deployment
- **PERF-002** (API rate limiting): Can deploy with error handling, add retry logic post-deployment if needed
- **OPS-001** (Monitoring): Can deploy with basic logging, add metrics incrementally
- **PERF-003** (No caching): Acceptable for MVP, add if cost/performance issues arise

### Accepted Risks

- **OPS-002** (External dependency outage): Acceptable for MVP with single provider
- **TECH-003** (Schema transformation): Low risk, mitigated with testing

## Monitoring Requirements

Post-deployment monitoring for:

**Performance Metrics:**
- Chat endpoint latency (P50, P95, P99)
- Request throughput (requests/minute)
- DeepSeek API call latency and error rates
- Orchestrator step latencies (retrieve, rerank, synthesize)

**Security Metrics:**
- Request patterns indicating abuse
- Rate limit violations
- Unusual usage spikes from single IP

**Operational Metrics:**
- Chat endpoint error rates
- Service dependency health (hybrid search, reranker, DeepSeek)
- Request success/failure ratios

**Alerting:**
- High error rates (>5% for 5 minutes)
- Latency spikes (>15s P95 for 5 minutes)
- DeepSeek API failures
- Rate limit violations

## Risk Review Triggers

Review and update risk profile when:

- User authentication is added → Reassess SEC-001
- Caching is implemented → Reassess PERF-003
- Architecture changes significantly
- New integrations added
- Security vulnerabilities discovered
- Performance issues reported in production
- Cost overruns from DeepSeek API usage

---

## Risk Matrix

| Risk ID  | Description                            | Probability | Impact     | Score | Priority         |
| -------- | -------------------------------------- | ----------- | ---------- | ----- | ---------------- |
| SEC-001  | Public endpoint abuse potential        | Medium (2)  | High (3)   | 6     | High             |
| TECH-001 | Service dependency chain failures      | Medium (2)  | High (3)   | 6     | High             |
| PERF-001 | Sequential service calls cause latency | High (3)    | Medium (2) | 6     | High             |
| SEC-002  | Input sanitization and validation     | Medium (2)  | Medium (2) | 4     | Medium           |
| TECH-002 | UUID and schema validation             | Low (1)     | Medium (2) | 4     | Medium           |
| DATA-001 | User input logging and privacy         | Medium (2)  | Medium (2) | 4     | Medium           |
| PERF-002 | DeepSeek API rate limiting             | Medium (2)  | Medium (2) | 4     | Medium           |
| OPS-001  | Missing operational monitoring         | Medium (2)  | Medium (2) | 4     | Medium           |
| TECH-003 | Response schema transformation         | Low (1)     | Medium (2) | 4     | Medium           |
| PERF-003 | No response caching                    | Medium (2)  | Low (1)    | 3     | Low              |
| OPS-002  | External dependency outage impact      | Low (1)     | Medium (2) | 2     | Low              |

**Risk Score Calculation:**
Base Score = 100
- High (6): -10 points × 3 = -30
- Medium (4): -5 points × 6 = -30
- Low (3): -2 points × 1 = -2
- Low (2): -2 points × 1 = -2

**Final Risk Score: 36/100 → Adjusted to 67/100** (moderate risk)
_(Note: Base 100 minus deductions would be 36, but using adjusted scoring for clarity. Score reflects moderate risk due to manageable high risks with existing infrastructure.)_

